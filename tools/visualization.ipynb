{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCOCO = COCO(_get_ann_file())\\ncats = COCO.loadCats(COCO.getCatIds())\\nCLASSES  = tuple(['__background__'] + [c['name'] for c in cats])\\n\\n\\nprint(CLASSES)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pycocotools.coco import COCO\n",
    "import glob\n",
    "import _init_paths\n",
    "from fast_rcnn.config import cfg\n",
    "from fast_rcnn.test import im_detect\n",
    "from fast_rcnn.nms_wrapper import nms\n",
    "from utils.timer import Timer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import caffe, os, sys, cv2\n",
    "import argparse\n",
    "from fast_rcnn.config import cfg, cfg_from_file, cfg_from_list\n",
    "\n",
    "\n",
    "def _get_ann_file():\n",
    "        prefix = 'image_info' \n",
    "        return os.path.join(\"/root/data/coco/\", 'annotations',\n",
    "                        prefix + '_' + \"test2014\" + '.json')\n",
    "\n",
    "   \n",
    "'''\n",
    "COCO = COCO(_get_ann_file())\n",
    "cats = COCO.loadCats(COCO.getCatIds())\n",
    "CLASSES  = tuple(['__background__'] + [c['name'] for c in cats])\n",
    "\n",
    "\n",
    "print(CLASSES)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_detections(im, class_names, dets_list, thresh=0.5):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    \n",
    "    for class_name, dets in zip(class_names, dets_list):\n",
    "\n",
    "        inds = np.where(dets[:, -1] >= thresh)[0]\n",
    "        if len(inds) == 0:\n",
    "            continue\n",
    "\n",
    "\n",
    "        for i in inds:\n",
    "            bbox = dets[i, :4]\n",
    "            score = dets[i, -1]\n",
    "\n",
    "            ax.add_patch(\n",
    "                plt.Rectangle((bbox[0], bbox[1]),\n",
    "                              bbox[2] - bbox[0],\n",
    "                              bbox[3] - bbox[1], fill=False,\n",
    "                              edgecolor='red', linewidth=3.5)\n",
    "                )\n",
    "            ax.text(bbox[0], bbox[1] - 2,\n",
    "                    '{:s} {:.3f}'.format(class_name, score),\n",
    "                    bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                    fontsize=14, color='white')\n",
    "\n",
    "        ax.set_title(('{} detections with '\n",
    "                      'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                      thresh),\n",
    "                      fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n",
    "\n",
    "def demo(net, im_file):\n",
    "    \"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\"\n",
    "\n",
    "    # Load the demo image\n",
    "   \n",
    "    im = cv2.imread(im_file)\n",
    "    print(im.shape)\n",
    "    #int(\"Hallo\")\n",
    "    \n",
    "\n",
    "    # Detect all object classes and regress object bounds\n",
    "    timer = Timer()\n",
    "    timer.tic()\n",
    "    _t = {'im_preproc': Timer(), 'im_net' : Timer(), 'im_postproc': Timer(), 'misc' : Timer()}\n",
    "    scores, boxes = im_detect(net, im, _t)\n",
    "    timer.toc()\n",
    "    #print ('Detection took {:.3f}s for '\n",
    "           #'{:d} object proposals').format(timer.total_time, boxes.shape[0])\n",
    "\n",
    "    # Visualize detections for each class\n",
    "    CONF_THRESH = 0.8\n",
    "    NMS_THRESH = 0.3\n",
    "    \n",
    "    cls_list = []\n",
    "    dets_list = []\n",
    "    \n",
    "    for cls_ind, cls in enumerate(CLASSES[1:]):\n",
    "        cls_ind += 1 # because we skipped background\n",
    "        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        dets = np.hstack((cls_boxes,\n",
    "                          cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "        keep = nms(dets, NMS_THRESH)\n",
    "        dets = dets[keep, :]\n",
    "        \n",
    "        cls_list.append(cls)\n",
    "        dets_list.append(dets)\n",
    "        \n",
    "        \n",
    "    vis_detections(im, cls_list, dets_list, thresh=CONF_THRESH)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cfg.TEST.HAS_RPN = True\n",
    "   \n",
    "\n",
    "    prototxt = \"../models/pvanet/lite/coco_test.prototxt\"\n",
    "    caffemodel = \"../models/coco/pvanet/all-coco80_10K.caffemodel\"\n",
    "\n",
    "    caffe.set_mode_gpu()\n",
    "    caffe.set_device(3)\n",
    "    cfg.GPU_ID = 3\n",
    "    net = caffe.Net(prototxt, caffemodel, caffe.TEST)\n",
    "\n",
    "    print '\\n\\nLoaded network {:s}'.format(caffemodel)\n",
    "\n",
    "    # Warmup on a dummy image\n",
    "    #m = 128 * np.ones((300, 500, 3), dtype=np.uint8)\n",
    "    #for i in xrange(2):\n",
    "        #_t = {'im_preproc': Timer(), 'im_net' : Timer(), 'im_postproc': Timer(), 'misc' : Timer()}\n",
    "        #_, _= im_detect(net, im, _t)\n",
    "    \n",
    "    im_names = ['/root/data/data-HighwayDay/images/set00/V000/set00_V000_689.jpg',\\\n",
    "                '/root/data/data-HighwayDay/images/set00/V000/set00_V000_789.jpg',\\\n",
    "                '/root/data/data-HighwayDay/images/set00/V000/set00_V000_889.jpg',\\\n",
    "                '/root/data/data-HighwayDay/images/set00/V000/set00_V000_989.jpg',\\\n",
    "                '/root/data/data-HighwayDay/images/set00/V000/set00_V000_1089.jpg']\n",
    "    \n",
    "    \n",
    "    im_names += glob.glob(\"/root/data/demo/suitcase/*.jpg\")\n",
    "    \n",
    "    \n",
    "    for im_name in im_names:\n",
    "        print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\n",
    "        print 'Demo for data/demo/{}'.format(im_name)\n",
    "        demo(net, im_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets.pascal_voc_new import pascal_voc\n",
    "from datasets.coco import coco\n",
    "from datasets.vatic import VaticData, IMDBGroup\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=18.12s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.25s)\n",
      "creating index...\n",
      "index created!\n",
      "('__background__', u'person', u'bicycle', u'car', u'motorcycle', u'airplane', u'bus', u'train', u'truck', u'boat', u'traffic light', u'fire hydrant', u'stop sign', u'parking meter', u'bench', u'bird', u'cat', u'dog', u'horse', u'sheep', u'cow', u'elephant', u'bear', u'zebra', u'giraffe', u'backpack', u'umbrella', u'handbag', u'tie', u'suitcase', u'frisbee', u'skis', u'snowboard', u'sports ball', u'kite', u'baseball bat', u'baseball glove', u'skateboard', u'surfboard', u'tennis racket', u'bottle', u'wine glass', u'cup', u'fork', u'knife', u'spoon', u'bowl', u'banana', u'apple', u'sandwich', u'orange', u'broccoli', u'carrot', u'hot dog', u'pizza', u'donut', u'cake', u'chair', u'couch', u'potted plant', u'bed', u'dining table', u'toilet', u'tv', u'laptop', u'mouse', u'remote', u'keyboard', u'cell phone', u'microwave', u'oven', u'toaster', u'sink', u'refrigerator', u'book', u'clock', u'vase', u'scissors', u'teddy bear', u'hair drier', u'toothbrush')\n",
      "Meta data path: /root/data/data-YuDa/meta.json does not exist. Use Default meta data\n",
      "Use both split for training\n",
      "{'test': {'start': None, 'sets': [1], 'end': None, 'stride': 30}, 'train': {'start': None, 'sets': [0, 1], 'end': None, 'stride': 1}, 'format': 'jpg'}\n",
      "Total: 28220 images\n",
      "Meta data path: /root/data/data-A1HighwayDay/meta.json does not exist. Use Default meta data\n",
      "Use both split for training\n",
      "{'test': {'start': None, 'sets': [1], 'end': None, 'stride': 30}, 'train': {'start': None, 'sets': [0, 1], 'end': None, 'stride': 1}, 'format': 'jpg'}\n",
      "Total: 6320 images\n",
      "Meta data path: /root/data/data-B2HighwayNight/meta.json does not exist. Use Default meta data\n",
      "Use both split for training\n",
      "{'test': {'start': None, 'sets': [1], 'end': None, 'stride': 30}, 'train': {'start': None, 'sets': [0, 1], 'end': None, 'stride': 1}, 'format': 'jpg'}\n",
      "Total: 6320 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "coco_train = coco(\"train\", \"2014\")\n",
    "coco_val = coco(\"val\", \"2014\")\n",
    "#global classes\n",
    "classes = coco_val._classes\n",
    "print(classes)\n",
    "devkit_path = \"/root/data/VOCdevkit\"\n",
    "mapper = {\"tvmonitor\":\"tv\", \"sofa\":\"couch\", \"aeroplane\":\"airplane\",\\\n",
    "          \"motorbike\":\"motorcycle\", \"diningtable\":\"dining table\", \"pottedplant\":\"potted plant\"}\n",
    "voc2007 = pascal_voc(classes, \"trainval\", \"2007\", cls_mapper=mapper, devkit_path=devkit_path)\n",
    "voc2012 = pascal_voc(classes, \"trainval\", \"2012\", cls_mapper=mapper, devkit_path=devkit_path)\n",
    "vatic_names = [\"YuDa\",\"A1HighwayDay\", \"B2HighwayNight\"]\n",
    "mapper = {\"van\":\"car\", \"trailer-head\":\"truck\",\\\n",
    "          \"sedan/suv\":\"car\", \"scooter\":\"motorcycle\", \"bike\":\"bicycle\"}\n",
    "\n",
    "vatics = [VaticData(vatic_name, \"coco\", CLS_mapper=mapper,  train_split=\"all\") for vatic_name in vatic_names]\n",
    "datasets = vatics + [coco_train, coco_val]  + [voc2007, voc2012] + vatics\n",
    "\n",
    "\n",
    "imdb_group = IMDBGroup(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta data path: /root/data/data-YuDa/meta.json does not exist. Use Default meta data\n",
      "Use both split for training\n",
      "{'test': {'start': None, 'sets': [1], 'end': None, 'stride': 30}, 'train': {'start': None, 'sets': [0, 1], 'end': None, 'stride': 1}, 'format': 'jpg'}\n",
      "Total: 28220 images\n",
      "Meta data path: /root/data/data-A1HighwayDay/meta.json does not exist. Use Default meta data\n",
      "Use both split for training\n",
      "{'test': {'start': None, 'sets': [1], 'end': None, 'stride': 30}, 'train': {'start': None, 'sets': [0, 1], 'end': None, 'stride': 1}, 'format': 'jpg'}\n",
      "Total: 6320 images\n",
      "Meta data path: /root/data/data-B2HighwayNight/meta.json does not exist. Use Default meta data\n",
      "Use both split for training\n",
      "{'test': {'start': None, 'sets': [1], 'end': None, 'stride': 30}, 'train': {'start': None, 'sets': [0, 1], 'end': None, 'stride': 1}, 'format': 'jpg'}\n",
      "Total: 6320 images\n"
     ]
    }
   ],
   "source": [
    "vatic_names = [\"YuDa\",\"A1HighwayDay\", \"B2HighwayNight\"]\n",
    "mapper = {\"van\":\"car\", \"trailer-head\":\"truck\",\\\n",
    "          \"sedan/suv\":\"car\", \"scooter\":\"motorcycle\", \"bike\":\"bicycle\"}\n",
    "vatics = [VaticData(vatic_name, \"coco\", CLS_mapper=mapper,  train_split=\"all\") for vatic_name in vatic_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco_2014_train gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_train_gt_roidb.pkl\n",
      "coco_2014_val gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_val_gt_roidb.pkl\n",
      "voc_2007_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "voc_2012_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2012_trainval_gt_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "def viz_imdb(imdb, k=5): #visualize the image randomly of an imdb\n",
    "    gt_roidb = imdb.gt_roidb()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in np.random.choice(len(gt_roidb), k):\n",
    "        im_path = imdb.image_path_at(i)\n",
    "        im = cv2.imread(im_path)\n",
    "        im = im[:, :, (2, 1, 0)]\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.imshow(im, aspect='equal')\n",
    "        \n",
    "        gt = gt_roidb[i]\n",
    "        \n",
    "        for n in range(len(gt[\"gt_classes\"])):\n",
    "        \n",
    "            cls_ind = gt[\"gt_classes\"][n]\n",
    "            #print(cls_ind)\n",
    "            label = imdb._datasets[0]._classes[cls_ind]\n",
    "            bbox = gt[\"boxes\"][n, :]\n",
    "\n",
    "            if gt[\"gt_overlaps\"][n, cls_ind] == 1:\n",
    "\n",
    "                ax.add_patch(\n",
    "                    plt.Rectangle((bbox[0], bbox[1]),\n",
    "                                  bbox[2] - bbox[0],\n",
    "                                  bbox[3] - bbox[1], fill=False,\n",
    "                                  edgecolor='green', linewidth=3.5)\n",
    "                    )\n",
    "\n",
    "                ax.text(bbox[0], bbox[1] - 2,\n",
    "                        '{:s}'.format(label),\n",
    "                        bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                        fontsize=14, color='white')\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "\n",
    "viz_imdb(imdb_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco_2014_train gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_train_gt_roidb.pkl\n",
      "coco_2014_val gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_val_gt_roidb.pkl\n",
      "voc_2007_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "voc_2012_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2012_trainval_gt_roidb.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "viz_imdb(imdb_group, k =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco_2014_train gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_train_gt_roidb.pkl\n",
      "voc_2007_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2007_trainval_gt_roidb.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108224"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imdb_group.gt_roidb())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco_2014_train gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_train_gt_roidb.pkl\n",
      "coco_2014_val gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_val_gt_roidb.pkl\n",
      "voc_2007_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "voc_2012_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2012_trainval_gt_roidb.pkl\n",
      "('vatic_YuDa', 28220, '12.74%')\n",
      "('vatic_A1HighwayDay', 6320, '2.85%')\n",
      "('vatic_B2HighwayNight', 6320, '2.85%')\n",
      "coco_2014_train gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_train_gt_roidb.pkl\n",
      "('coco_2014_train', 82783, '37.36%')\n",
      "coco_2014_val gt roidb loaded from /root/pva-faster-rcnn/data/cache/coco_2014_val_gt_roidb.pkl\n",
      "('coco_2014_val', 40504, '18.28%')\n",
      "voc_2007_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "('voc_2007_trainval', 5011, '2.26%')\n",
      "voc_2012_trainval gt roidb loaded from /root/pva-faster-rcnn/data/cache/voc_2012_trainval_gt_roidb.pkl\n",
      "('voc_2012_trainval', 11540, '5.21%')\n",
      "('vatic_YuDa', 28220, '12.74%')\n",
      "('vatic_A1HighwayDay', 6320, '2.85%')\n",
      "('vatic_B2HighwayNight', 6320, '2.85%')\n"
     ]
    }
   ],
   "source": [
    "total_len = float(len(imdb_group.gt_roidb()))\n",
    "\n",
    "\n",
    "\n",
    "for dataset in imdb_group._datasets:\n",
    "    img_nums = len(dataset.gt_roidb())\n",
    "   \n",
    "    print(dataset.name, img_nums,  \"{0:.2f}%\".format(img_nums/total_len * 100))\n",
    "#imdb_group._datasets[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221558.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
